{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET_decov.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2bOKqhAS7Rq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqn9A_mJTBiA"
      },
      "source": [
        "#please run this cell, it installs MMCV which is required to use deformable convolutions. This takes around 10 mins to complete installation\n",
        "!pip install mmcv-full\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO5IQ0vrThHE"
      },
      "source": [
        "from mmcv.ops import DeformConv2dPack"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b0k_geL-_OZ"
      },
      "source": [
        "def G_noise(image,mu,sigma):\n",
        "  img=np.array(image).astype(np.int16)\n",
        "  t=np.zeros(img.shape,np.int16)\n",
        "  img=img+cv2.randn(t,mu,sigma)\n",
        "  img[img<0]=0\n",
        "  img[img>255]=255\n",
        "  img = img.astype(np.uint8)\n",
        "  #image = PIL.Image.fromarray(img)\n",
        "  image=img\n",
        "  return image\n",
        "\n",
        "def transform(image):\n",
        "  mu=random.randint(0,15)\n",
        "  sigma=random.randint(30,90)\n",
        "  a=G_noise(image,mu,sigma)\n",
        "  \n",
        "  return a"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWMhx8KTVLIh"
      },
      "source": [
        "#unet Block\n",
        "def double_conv_layer(in_channels, filter):\n",
        "  return nn.Sequential(\n",
        "  DeformConv2dPack(in_channels=in_channels,out_channels=filter,kernel_size=(3,3),padding=(1,1)),\n",
        "  nn.BatchNorm2d(num_features=filter),\n",
        "  nn.ReLU(inplace=True),\n",
        "  DeformConv2dPack(in_channels=filter,out_channels=filter,kernel_size=(3,3),padding=(1,1)),\n",
        "  nn.BatchNorm2d(num_features=filter),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Dropout2d(p=0.1))\n",
        "\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa69KTmU_bZM"
      },
      "source": [
        "#defining the network\n",
        "class unet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(unet,self).__init__()\n",
        "    self.d1=double_conv_layer(1,32)\n",
        "    self.p1=nn.MaxPool2d(kernel_size=2,stride=(2,2))\n",
        "    self.d2=double_conv_layer(32,64)\n",
        "   \n",
        "    self.d3=double_conv_layer(64,128)\n",
        "   \n",
        "    self.d4=double_conv_layer(128,256)\n",
        "    self.d5=double_conv_layer(256,512)    \n",
        "    self.bottle=double_conv_layer(512,1024)\n",
        "\n",
        "    self.u5=nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=(2,2),stride=(2,2))\n",
        "    self.ul5=double_conv_layer(1024,512)\n",
        "    self.u4=nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=(2,2),stride=(2,2))\n",
        "    self.ul4=double_conv_layer(512,256)\n",
        "    self.u3=nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=(2,2),stride=(2,2))\n",
        "    self.ul3=double_conv_layer(256,128)\n",
        "\n",
        "    self.u2=nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=(2,2),stride=(2,2))\n",
        "    self.ul2=double_conv_layer(128,64)\n",
        "\n",
        "    self.u1=nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=(2,2),stride=(2,2))\n",
        "    self.ul1=double_conv_layer(64,32)\n",
        "    \n",
        "    self.ol=nn.Conv2d(in_channels=32,out_channels=2,kernel_size=(1,1))\n",
        "\n",
        "    self.sig=nn.Sigmoid()\n",
        "  def forward(self,X):\n",
        "    down1=self.d1(X)\n",
        "    pool1=self.p1(down1)\n",
        "    \n",
        "    down2=self.d2(pool1)\n",
        "    pool2=self.p1(down2)\n",
        "    \n",
        "    down3=self.d3(pool2)\n",
        "    pool3=self.p1(down3)\n",
        "\n",
        "    down4=self.d4(pool3)\n",
        "    #print(down4.shape)\n",
        "    pool4=self.p1(down4)\n",
        "    \n",
        "    down5=self.d5(pool4)\n",
        "    pool5=self.p1(down5)\n",
        "    \n",
        "    bottleneck=self.bottle(pool5)\n",
        "    \n",
        "    up5=self.u5(bottleneck)\n",
        "    up5=torch.cat([up5,down5],dim=1)\n",
        "    up5=self.ul5(up5)\n",
        "    \n",
        "    up4=self.u4(up5)\n",
        "    up4=torch.cat([up4,down4],dim=1)\n",
        "    up4=self.ul4(up4)\n",
        "    \n",
        "    up3=self.u3(up4)\n",
        "    up3=torch.cat([up3,down3],dim=1)\n",
        "    up3=self.ul3(up3)\n",
        "\n",
        "    up2=self.u2(up3)\n",
        "    up2=torch.cat([up2,down2],dim=1)\n",
        "    up2=self.ul2(up2)\n",
        "    \n",
        "    up1=self.u1(up2)\n",
        "    up1=torch.cat([up1,down1],dim=1)\n",
        "    up1=self.ul1(up1)\n",
        "    \n",
        "    out=self.ol(up1)\n",
        "    \n",
        "    out=self.sig(out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-9-WOdR_g_e"
      },
      "source": [
        "model=unet()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHKipnV-_jz6",
        "outputId": "c701002f-1f58-4683-e7fb-2bd055823e06"
      },
      "source": [
        "#transferring the device to GPU\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model=model.to(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FqkOvdJ_t6J"
      },
      "source": [
        "#getting the important libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJRrXFuY_ufU",
        "outputId": "a6c197ed-499e-4ee9-904b-24c4d2cf66e0"
      },
      "source": [
        "#mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqkZomXW_wtN"
      },
      "source": [
        "#please ignore this cell\n",
        "'''#adding border\n",
        "def add_border(img: np.array, size_x: int = 128, size_y: int = 128) -> (np.array, int, int):\n",
        "    \"\"\"Add border to image, so it will divide window sizes: size_x and size_y\"\"\"\n",
        "    max_y, max_x = img.shape[:2]\n",
        "    border_y = 0\n",
        "    if max_y % size_y != 0:\n",
        "        border_y = (size_y - (max_y % size_y) + 1) // 2\n",
        "        img = cv2.copyMakeBorder(img, border_y, border_y, 0, 0, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
        "    border_x = 0\n",
        "    if max_x % size_x != 0:\n",
        "        border_x = (size_x - (max_x % size_x) + 1) // 2\n",
        "        img = cv2.copyMakeBorder(img, 0, 0, border_x, border_x, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
        "    return img, border_y, border_x\n",
        "\n",
        "\n",
        "    #preprocessing\n",
        "def split_img(img: np.array, size_x: int = 128, size_y: int = 128 )-> [np.array]:\n",
        "    \"\"\"Split image to parts (little images).\n",
        "    Walk through the whole image by the window of size size_x * size_y without overlays and\n",
        "    save all parts in list. Images sizes should divide window sizes.\n",
        "    \"\"\"\n",
        "    max_y, max_x = img.shape[:2]\n",
        "    parts = []\n",
        "    curr_y = 0\n",
        "    # TODO: rewrite with generators.\n",
        "    while (curr_y + size_y) <= max_y:\n",
        "        curr_x = 0\n",
        "        while (curr_x + size_x) <= max_x:\n",
        "            parts.append(img[curr_y:curr_y + size_y, curr_x:curr_x + size_x])\n",
        "            curr_x += size_x\n",
        "        curr_y += size_y\n",
        "    return parts\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBVTuI5SYfYU"
      },
      "source": [
        "#adding border\n",
        "def add_border(img: np.array, size_x: int = 128, size_y: int = 128) -> (np.array, int, int):\n",
        "    \"\"\"Add border to image, so it will divide window sizes: size_x and size_y\"\"\"\n",
        "    max_y, max_x = img.shape[:2]\n",
        "    border_y = 0\n",
        "    if max_y % size_y != 0:\n",
        "        a = (size_y - (max_y % size_y) + 1)\n",
        "       # print('a=',a)\n",
        "        l=0\n",
        "        r=0\n",
        "        if a%2!=0:\n",
        "          l=a//2\n",
        "          r=a//2\n",
        "        else:\n",
        "          l=a//2\n",
        "          r=(a//2)-1\n",
        "        #print(l,r)\n",
        "        img = cv2.copyMakeBorder(img, l, r, 0, 0, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
        "        \n",
        "    border_x = 0\n",
        "    if max_x % size_x != 0:\n",
        "        a = (size_x - (max_x % size_x) + 1)\n",
        "        l=0\n",
        "        r=0\n",
        "        if a%2!=0:\n",
        "          l=a//2\n",
        "          r=a//2\n",
        "        else:\n",
        "          l=a//2\n",
        "          r=(a//2)-1\n",
        "        #print(l,r)\n",
        "        img = cv2.copyMakeBorder(img, 0, 0, l, r, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
        "    return img, border_y, border_x\n",
        "\n",
        "\n",
        "    #preprocessing\n",
        "def split_img(img: np.array, size_x: int = 128, size_y: int = 128 )-> [np.array]:\n",
        "    \"\"\"Split image to parts (little images).\n",
        "    Walk through the whole image by the window of size size_x * size_y without overlays and\n",
        "    save all parts in list. Images sizes should divide window sizes.\n",
        "    \"\"\"\n",
        "    max_y, max_x = img.shape[:2]\n",
        "    parts = []\n",
        "    curr_y = 0\n",
        "    # TODO: rewrite with generators.\n",
        "    while (curr_y + size_y) <= max_y:\n",
        "        curr_x = 0\n",
        "        while (curr_x + size_x) <= max_x:\n",
        "            parts.append(img[curr_y:curr_y + size_y, curr_x:curr_x + size_x])\n",
        "            curr_x += size_x\n",
        "        curr_y += size_y\n",
        "    return parts"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkiJdl-K_47b",
        "outputId": "f76c0a9b-b378-4562-e323-2c8f34f3a919"
      },
      "source": [
        "# getting the images from drive for training\n",
        "\n",
        "get_printed=glob.glob('/content/drive/MyDrive/Siddharth-Binarization/dataset_DIBCO/*')\n",
        "print(len(get_printed))\n",
        "\n",
        "images_in=[]\n",
        "images_gt=[]\n",
        "for paths in get_printed:\n",
        "  n=len(glob.glob(paths+\"/*_in.png\"))\n",
        "  for i in range(1,n+1):\n",
        "    if (i<10):\n",
        "      f_name_in=os.path.join(paths,\"0\"+str(i)+\"_in.png\")\n",
        "      f_name_gt=os.path.join(paths,\"0\"+str(i)+\"_gt.png\")\n",
        "    else :\n",
        "      f_name_in=os.path.join(paths,str(i)+\"_in.png\")\n",
        "      f_name_gt=os.path.join(paths,str(i)+\"_gt.png\")\n",
        "\n",
        "    images_in.append(cv2.imread(f_name_in,cv2.IMREAD_GRAYSCALE))\n",
        "    images_gt.append(cv2.imread(f_name_gt,cv2.IMREAD_GRAYSCALE))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJNsdcrWApoz",
        "outputId": "8a0d0aa8-2bff-4339-c009-1fafa8d0600c"
      },
      "source": [
        "size=len(images_in)\n",
        "for i in range(size):\n",
        "  a=transform(images_in[i])\n",
        "  images_in.append(a)\n",
        "  images_gt.append(images_gt[i])\n",
        "print(len(images_in))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99pZS6hS_7kL",
        "outputId": "a2b7fec7-f63b-46f1-9de0-34ddc5ae58b8"
      },
      "source": [
        "#splitting the images into 128X128 images for training\n",
        "images_in=np.array(images_in)\n",
        "images_gt=np.array(images_gt)\n",
        "print(images_gt.shape)\n",
        "\n",
        "in_set=[]\n",
        "gt_set=[]\n",
        "n=images_in.shape[0]\n",
        "for i in range(n):\n",
        "  img_in,_,_=add_border(images_in[i])\n",
        "  img_gt,_,_=add_border(images_gt[i])\n",
        "  parts1=split_img(img_in)\n",
        "  parts2=split_img(img_gt)\n",
        "  for img in parts1:\n",
        "    in_set.append(img)\n",
        "  for img in parts2:\n",
        "    gt_set.append(img)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIT0jwKdHHDX",
        "outputId": "1d997005-89f2-485d-a962-59787cdebc59"
      },
      "source": [
        "cd drive/My Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ediqkaHADGI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYGGS76fATFH",
        "outputId": "5212c4e8-fba7-4d12-d526-824281099020"
      },
      "source": [
        "# resizing the tensor to pytorch format for training in pytorch\n",
        "in_set=np.array(in_set)\n",
        "gt_set=np.array(gt_set)\n",
        "print(gt_set.shape)\n",
        "\n",
        "num_samples=in_set.shape[0]\n",
        "in_set.resize((num_samples,1,128,128))\n",
        "#gt_set.resize((num_samples,1,128,128))\n",
        "print(in_set.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4242, 128, 128)\n",
            "(4242, 1, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrFNnpMvAWhX"
      },
      "source": [
        "#function to invert the images\n",
        "def invert(gt_set):\n",
        "  for i,im in enumerate(gt_set):\n",
        "    #print(i)\n",
        "    gt_set[i]=255-gt_set[i]\n",
        "  return gt_set"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "WvK2tWT-AZBY",
        "outputId": "03b9b98f-aae6-44b6-e2a6-45e41eeb0ac7"
      },
      "source": [
        "#inverting the ground truth images\n",
        "gt_set=invert(gt_set)\n",
        "cv2_imshow(gt_set[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAACX0lEQVR4nO2b2ZbDIAiG45x5/1dmLrokjawC6pnyX7RZ5RPRWGyOo1QqlUrfrma8HgbuYfVjt//4WAMAH1/zAUKrTgKAbCYyCDoAoCua4YAOgImy99HMXsBUMse+PgiT7BMAKa1tAeiVhvS71rwSALCdoFjQNIHQK/MBCMUQKAByu4QMkNwlCQCN1ZgodMRAjGQAqqLJ3VBqgxb1SNCNhHfrQcZHAIKfheYgDLe/XS84azhrSrCbBwoAC/P4yOcApqsA9gPIDTkFAKsEuv2aoNfsWTHj5oz4iGkCRVonFYBJ68wBeELEAswaDyI8AJfPXADexhjB0O8Cwi6MtJsb4J49sTJQTYCX03m5HwCsDYHkirnLgd0dIbAmKMIfDAQA3ZLRBKIH3I3sBWCFOcrYDbD1AgtBZy6qG9IFNm7Xnjgx54hYoIGREF0xuVkQim3I1jgAWlIjz/ilW7LhzTbVVToAqqS86QkGYJ4XN+k2I4DV/iNOB52kBWic/cOROVV7YLyOYrlXhf89QNSGP04nJwj288DsDMlNExeNS6VSqVQqlZ5aNQGCl/VFc8Lz37FrAODc2G9W/BUA17n3ag/AaoDlHmj+FROX+UUeuKbV1jSBJ6v177TIDefy2shLLshN2HodkGW/n8V2gOcgiuTW7gcJ0kshj7NDL7koVtI068lgBgBkC6fiLH+e848DOJXWvglANAD0BlnIqAcYE7o3VbwAryiTwpFdbAYPAGGwO0rvHNZZsWLl3Pwfi/WzYsuUDB2A5UNC3/G84kE1AjpQE2oWAPeTE1sOTIkBkhQ58QdHc3+pCmanHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F62187DEB50>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btcRncpZAbC-"
      },
      "source": [
        "#normalizing the pixel values\n",
        "in_set=in_set/255\n",
        "gt_set=gt_set/255"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy8rS0R7AqZS"
      },
      "source": [
        "#getting the test set\n",
        "in_test=in_set[4142:4242]\n",
        "gt_test=gt_set[4142:4242]\n",
        "in_set=in_set[0:4142]\n",
        "gt_set=gt_set[0:4142]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWIkILLDEa3o"
      },
      "source": [
        "#transferring all the tensors to the gpu\n",
        "in_test=torch.tensor(in_test,device=device,dtype=torch.float32)\n",
        "gt_test=torch.tensor(gt_test,device=device,dtype=torch.long)\n",
        "in_set=torch.tensor(in_set,device=device,dtype=torch.float32)\n",
        "gt_set=torch.tensor(gt_set,device=device,dtype=torch.long)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4abRRLfgDBHV"
      },
      "source": [
        "#preparation for training\n",
        "lr=0.005 #learning rate\n",
        "batch_size=32\n",
        "\n",
        "loss_func=nn.CrossEntropyLoss()\n",
        "opti=optim.Adam(model.parameters(),lr=lr)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiVdC__1DDSl",
        "outputId": "4f651769-7f91-4d17-9a0e-4423a0a39aa6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLKtuMe_DFs-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_k7-JpK30Wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26244176-6ecc-417b-8fae-1dd1c7d3a2c3"
      },
      "source": [
        "#training the model for num_epochs\n",
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "  #perm=torch.randperm(in_set.size()[0])\n",
        "  #perm=perm-1\n",
        "  n=in_set.size()[0]\n",
        "  print(epoch)\n",
        "  for i in range(0,n,batch_size):\n",
        "    opti.zero_grad()\n",
        "    #indices=perm[i:i+batch_size]\n",
        "    \n",
        "    X=in_set[i:i+batch_size]\n",
        "   \n",
        "    scores=model.forward(X)\n",
        "    loss=loss_func(scores,gt_set[i:i+batch_size])\n",
        "\n",
        "    loss.backward()\n",
        "    opti.step()\n",
        "\n",
        "    if i%1024 is 0:\n",
        "      print(loss.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0.3729095458984375\n",
            "0.3510158360004425\n",
            "0.3784761130809784\n",
            "0.4287142753601074\n",
            "0.45006120204925537\n",
            "1\n",
            "0.4334586560726166\n",
            "0.3476353585720062\n",
            "0.3706762194633484\n",
            "0.4222213625907898\n",
            "0.4353606402873993\n",
            "2\n",
            "0.40946850180625916\n",
            "0.34251296520233154\n",
            "0.3607695996761322\n",
            "0.4103763997554779\n",
            "0.41698190569877625\n",
            "3\n",
            "0.39938995242118835\n",
            "0.3387882113456726\n",
            "0.35122430324554443\n",
            "0.40702199935913086\n",
            "0.40725311636924744\n",
            "4\n",
            "0.3816050589084625\n",
            "0.33448824286460876\n",
            "0.35472288727760315\n",
            "0.4146418273448944\n",
            "0.40042322874069214\n",
            "5\n",
            "0.38085880875587463\n",
            "0.34413260221481323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc6DVn_1ENDz"
      },
      "source": [
        "# torch.save(model.state_dict(),'/content/drive/My Drive/Siddharth-Binarization/model_deconv_20eps_AG.pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbVzKQsV4no7"
      },
      "source": [
        "#checking accuracy\n",
        "x=model.forward(in_test[0:32])\n",
        "a,b=torch.max(x.data,dim=1,keepdims=True)\n",
        "sz=b.shape[0]\n",
        "num=0\n",
        "for i in range(sz):\n",
        "  num=num+b[i][0].eq(gt_test[i]).sum().item()\n",
        "denom+=sz*128*128\n",
        "print(num/denom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scpMS5wc51jT",
        "outputId": "dd8fba5c-4cef-4bb8-ef1a-d2cef5867f5a"
      },
      "source": [
        "print(num/denom)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03078369140625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivTm2jF04Ank"
      },
      "source": [
        "#loading the wrights\n",
        "m1=torch.load('/content/drive/My Drive/Siddharth-Binarization/model_deconv_5eps.pt')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxjLztG84Fie"
      },
      "source": [
        "# m2=unet()\n",
        "model.load_state_dict(m1)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7Fp6XSY4BBb"
      },
      "source": [
        "get_hr=glob.glob('/content/drive/My Drive/Siddharth-Binarization/hand_written/*')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBYN57le7X-o"
      },
      "source": [
        "#getting the handwritten image\n",
        "in_wr=cv2.imread(get_hr[0],cv2.IMREAD_GRAYSCALE)\n",
        "gt_wr=cv2.imread(get_hr[1],cv2.IMREAD_GRAYSCALE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVyvFaJF74np"
      },
      "source": [
        "in_wr=np.array(in_wr)\n",
        "gt_wr=np.array(gt_wr)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC6k5r1DCeVg"
      },
      "source": [
        "in_wr,_,_=add_border(in_wr)\n",
        "gt_wr,_,_=add_border(gt_wr)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYYWJjiPDFoC"
      },
      "source": [
        "iwr_set=split_img(in_wr)\n",
        "iwr_set=np.array(iwr_set)\n",
        "gwt_set=split_img(gt_wr)\n",
        "gwt_set=np.array(gwt_set)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iruDzVTFMcf",
        "outputId": "e666a1ab-ada5-47c7-8362-0ecbfa964ba4"
      },
      "source": [
        "print(gt_wr.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 640)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPK2jVt77-Mf"
      },
      "source": [
        "iwr_set=np.resize(iwr_set,(iwr_set.shape[0],1,iwr_set.shape[1],iwr_set.shape[2]))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfBBMZdy8N0H"
      },
      "source": [
        "iwr_set=torch.tensor(iwr_set,device=device,dtype=torch.float32)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdWcjWl68gUu"
      },
      "source": [
        "#gt_wr=np.resize(gt_wr,(1,in_wr.shape[0],in_wr.shape[1]))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYGDwmK_86pp"
      },
      "source": [
        "gt_wr=torch.tensor(gt_wr,device=device,dtype=torch.long)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xifu4tXg9E2e"
      },
      "source": [
        "iwr_set/=255\n",
        "x=model.forward(iwr_set)\n",
        "a,b=torch.max(x.data,dim=1,keepdims=True)\n",
        "for ind in range(20):\n",
        "  cv2_imshow(np.array((b[ind][0].cpu())*255))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AP9BSbsMLW3"
      },
      "source": [
        "a=torch.tensor([1,2,3])\n",
        "a.append([4,5,6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twrA51KyE01A"
      },
      "source": [
        "#function to generate a binarized image, given the gray scale image\n",
        "def predict(mode,image,device):\n",
        "  #print(image.shape)\n",
        "  image,_,_=add_border(image)\n",
        "  image=image/255\n",
        " # print(image.shape)\n",
        "  H=image.shape[0]\n",
        "  W=image.shape[1]\n",
        "  \n",
        "  img_set=split_img(image)\n",
        "  img_set=np.array(img_set)\n",
        "  # print(img_set.shape)\n",
        "  img_set=np.resize(img_set,(img_set.shape[0],1,img_set.shape[1],img_set.shape[2]))\n",
        "  img_set=torch.tensor(img_set,device=device,dtype=torch.float32)\n",
        "  \n",
        "  predict=model.forward(img_set)\n",
        "  predict.to('cpu')\n",
        "  \n",
        "  r=predict.shape[0]\n",
        "  _,b=torch.max(predict.data,dim=1,keepdims=True)\n",
        "  #print(b.shape)\n",
        "  b=b.cpu()\n",
        "  predictions=[]\n",
        "  for i in range(r):\n",
        "    #print(i)\n",
        "    predictions.append(b[i][0]*255)\n",
        "  #print(H,W)\n",
        "  i=0\n",
        "  j=0\n",
        "  k=0\n",
        "  ret=np.zeros((H,W))\n",
        "  #print(ret.shape)\n",
        "  while i<H :\n",
        "    j=0\n",
        "    while j<W:\n",
        "      #print(ret[i:i+128,j:j+128].shape)\n",
        "      ret[i:i+128,j:j+128]=predictions[k]\n",
        "      #print(k)\n",
        "      k=k+1\n",
        "      j+=128\n",
        "    i+=128\n",
        "  return ret"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xEWMIcd5QTqv",
        "outputId": "fe4d9ddd-0447-4d90-f063-0ee41b480d71"
      },
      "source": [
        "#displaying a test image\n",
        "#please run this cell after loading the model weights and loading the images, you can change the value of ind variable to change images\n",
        "ind=6\n",
        "disp=255-predict(model,images_in[ind],device)\n",
        "cv2_imshow(disp)\n",
        "cv2_imshow(images_gt[ind])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=640x640 at 0x7F6217E76B50>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=600x564 at 0x7F6217E76790>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GeEZFKUPjS1"
      },
      "source": [
        "gim,_,_=add_border(gt_wr)\n",
        "gim=invert(gim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnKfibVbfqyO"
      },
      "source": [
        "r=predict(model,in_wr,device)\n",
        "cv2_imshow(255-r)\n",
        "cv2_imshow(gim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyO1IO0qgZkg"
      },
      "source": [
        "def accuracy(img1,img2):\n",
        "  img1=torch.tensor(img1)\n",
        "  img2=torch.tensor(img2)\n",
        "  num=img1.eq(img2).sum().item()\n",
        "  denom=img1.shape[0]*img1.shape[1]\n",
        "  ans=num/denom\n",
        "  return ans"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6PMm2-PiY-"
      },
      "source": [
        "ind=33\n",
        "disp=255-predict(model,images_in[ind],device)\n",
        "tar,_,_=add_border(images_gt[ind%31])\n",
        "print(accuracy(disp,tar))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRfpKy4aPzmr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhtqPQK1__eZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNoBWgfQB8jZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}